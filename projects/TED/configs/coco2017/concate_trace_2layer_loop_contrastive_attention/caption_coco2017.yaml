includes:
- ../../../../../mmf/configs/datasets/coco2017/traced_caption_anno_lmdb.yaml

model_config:
    traced_encoder_decoder:
      concate_trace: true
      base_model_name: 2layer-base
      max_gen_length: 225
      loop_contrastive: true
      tc_contrastive_aggregate_method: transformer
      losses:
      - type: caption_cross_entropy
      - type: in_batch_contrastive
        params:
          temperature: 1
      - type: ln_attention_supervision
      image_feature_processor:
        type: spatial
        params:
          module: linear
          feat_dim: 2048
          pos_dim: 5
          hidden_size: 768
          hidden_dropout_prob: 0.1

dataset_config:
  caption_coco2017:
    processors:
      caption_processor:
        params:
          max_seq_length: 225
          sync_seg_reverse: true
          sync_seg_shuffle: true
      trace_bbox_processor:
        params:
          sync_seg_reverse: true
          max_seq_length: 64

optimizer:
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 1000
    num_training_steps: 11000

training:
  clip_norm_mode: all
  clip_gradients: true
  max_grad_l2_norm: 0.25
  use_warmup: true
  warmup_factor: 0.2
  warmup_iterations: 1000
  batch_size: 32
  lr_scheduler: true
  num_workers: 0
  # Don't forget to update schedule_attributes if you update this
  max_updates: 88000
  find_unused_parameters: true
  early_stop:
    criteria: val/caption_coco2017/traced_bert_caption_bleu4
    minimize: false

evaluation:
  metrics:
  - traced_bert_caption_bleu4
# checkpoint:
#   pretrained_state_mapping:
#     model.bert: model.bert
